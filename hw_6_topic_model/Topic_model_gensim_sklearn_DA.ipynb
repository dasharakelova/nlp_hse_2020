{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import pyLDAvis.gensim\n",
    "import string\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "morph = MorphAnalyzer()\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лемматизация и токенизация, тут код без изменений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = set(stopwords.words('russian'))\n",
    "\n",
    "def opt_normalize(texts, top=None):\n",
    "    uniq = Counter()\n",
    "    for text in texts:\n",
    "        uniq.update(text)\n",
    "    \n",
    "    norm_uniq = {word:morph.parse(word)[0].normal_form for word, _ in uniq.most_common(top)}\n",
    "    \n",
    "    norm_texts = []\n",
    "    for text in texts:\n",
    "        \n",
    "        norm_words = [norm_uniq.get(word) for word in text]\n",
    "        norm_words = [word for word in norm_words if word and word not in stops]\n",
    "        norm_texts.append(norm_words)\n",
    "        \n",
    "    return norm_texts\n",
    "\n",
    "def tokenize(text):\n",
    "    words = [word.strip(string.punctuation) for word in text.split()]\n",
    "    words = [word for word in words if word]\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = open('wiki_data.txt', encoding='utf-8').read().splitlines()[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = opt_normalize([tokenize(text.lower()) for text in texts], 30000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавляем нграммы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph = gensim.models.Phrases(texts, scoring='npmi', threshold=0.6) # при значении в 0.4 нграммы были на мой вкус недостаточно \"устойчивые\"\n",
    "p = gensim.models.phrases.Phraser(ph)\n",
    "ngrammed_texts = p[texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['нижегородский',\n",
       " '—',\n",
       " 'сельский',\n",
       " 'посёлок',\n",
       " 'район',\n",
       " 'нижегородский',\n",
       " 'область',\n",
       " 'входить',\n",
       " 'состав',\n",
       " 'расположить',\n",
       " '12,5',\n",
       " 'километр',\n",
       " 'юг',\n",
       " 'село',\n",
       " '1',\n",
       " 'километр',\n",
       " 'запасть',\n",
       " 'город',\n",
       " 'право',\n",
       " 'берег_река',\n",
       " 'правый',\n",
       " 'приток',\n",
       " 'река',\n",
       " 'сатис',\n",
       " 'окружить',\n",
       " 'смешанный',\n",
       " 'леса',\n",
       " 'соединить',\n",
       " 'дорогой',\n",
       " 'посёлок',\n",
       " '1,5',\n",
       " 'километр',\n",
       " 'дорога',\n",
       " 'посёлок',\n",
       " 'сатис',\n",
       " '3,5',\n",
       " 'километр',\n",
       " 'название',\n",
       " 'являться',\n",
       " 'сугубо',\n",
       " 'официальный',\n",
       " 'местный',\n",
       " 'население',\n",
       " 'использовать',\n",
       " 'исключительно',\n",
       " 'название',\n",
       " '—',\n",
       " 'употребляться_языковой',\n",
       " 'оборот',\n",
       " 'ранее',\n",
       " 'использовать',\n",
       " 'название',\n",
       " '—',\n",
       " '1920-ха',\n",
       " 'год',\n",
       " 'переселенец',\n",
       " 'соседний',\n",
       " 'село',\n",
       " 'аламасовый',\n",
       " 'расположить',\n",
       " 'соответственно',\n",
       " '8',\n",
       " '14',\n",
       " 'километр',\n",
       " 'запасть',\n",
       " 'посёлок',\n",
       " 'жить',\n",
       " 'рабочий',\n",
       " 'совхоз',\n",
       " 'центр',\n",
       " 'посёлок',\n",
       " 'сатис',\n",
       " 'возле',\n",
       " 'посёлок',\n",
       " 'расположить',\n",
       " 'активно',\n",
       " 'камень',\n",
       " 'настоящее_время',\n",
       " 'официально',\n",
       " 'данные',\n",
       " '1978',\n",
       " 'год',\n",
       " 'посёлок',\n",
       " 'насчитываться',\n",
       " '24',\n",
       " 'хозяйство',\n",
       " '43',\n",
       " 'житель',\n",
       " 'осуществляться',\n",
       " 'колодец',\n",
       " 'учреждение',\n",
       " 'отсутствовать',\n",
       " '1992',\n",
       " 'год',\n",
       " 'посёлок',\n",
       " 'насчитываться',\n",
       " '7',\n",
       " 'хозяйство',\n",
       " '16',\n",
       " 'житель',\n",
       " 'который',\n",
       " '7',\n",
       " 'трудоспособный',\n",
       " 'возраст',\n",
       " '1',\n",
       " 'январь',\n",
       " '1995',\n",
       " 'год',\n",
       " 'посёлок',\n",
       " 'иметься',\n",
       " '6',\n",
       " 'хозяйство',\n",
       " '12',\n",
       " 'настоящее_время',\n",
       " 'посёлок',\n",
       " 'оставаться',\n",
       " 'получить',\n",
       " 'развитие',\n",
       " 'благодаря',\n",
       " 'свой',\n",
       " 'близость',\n",
       " 'святой',\n",
       " 'источник',\n",
       " 'расположить',\n",
       " 'казанский',\n",
       " '1,2',\n",
       " 'километр',\n",
       " '—',\n",
       " 'источник',\n",
       " 'святой',\n",
       " 'серафим',\n",
       " 'посёлок',\n",
       " 'расположить',\n",
       " '2012',\n",
       " 'год',\n",
       " 'освятить',\n",
       " 'храм',\n",
       " 'честь',\n",
       " 'серафим_саровский']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrammed_texts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA\n",
    "\n",
    "Составляем словарь. Удалять стоп-слова тут вроде не нужно, потому что мы от них избавились еще на этапе нормализации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_above=0.5, no_below=20)\n",
    "dictionary.compactify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(5782 unique tokens: ['1', '1,2', '1,5', '12', '14']...)\n"
     ]
    }
   ],
   "source": [
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем тексты в мешки слов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = gensim.models.TfidfModel(corpus, id2word=dictionary)\n",
    "corpus = tfidf[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь переходим к обучению. Обучим несколько моделей с разными параметрами и для каждой будем выводить полученные темы и считать перплексию.\n",
    "\n",
    "Сначала увеличим количество тем до 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lda_1 = gensim.models.LdaMulticore(corpus, 200, id2word=dictionary, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lda_1.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-13.003285654860283"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_1.log_perplexity(corpus[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем уменьшить количество тем, но сделать больше проходов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lda_2 = gensim.models.LdaMulticore(corpus, 75, id2word=dictionary, passes=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lda_2.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9.71470690425573"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_2.log_perplexity(corpus[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь вернемся к параметрам, которые ставили на паре, но изменим параметр alpha на asymmetric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 55s\n",
      "Parser   : 103 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lda_3 = gensim.models.LdaMulticore(corpus, 100, id2word=dictionary, passes=10, alpha='asymmetric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lda_3.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-10.906441646396885"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_3.log_perplexity(corpus[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В третьей модели с измененной альфой получилось меньше осмысленных тем (хотя они явно есть). А среди первых двух лучшие результаты показывает вторая, где было больше проходов и меньше топиков, перплексия у нее тоже минимальная. Вот удачные темы, которые она выделила:\n",
    "\n",
    "* 0.060*\"дорога\" + 0.043*\"железнодорожный\" + 0.038*\"посёлок\" + 0.037*\"станция\" + 0.037*\"железный\" + 0.032*\"километр\" + 0.017*\"линия\" + 0.017*\"проходить\" + 0.014*\"центр\" + 0.014*\"поезд\"')\n",
    "\n",
    "* 0.023*\"партия\" + 0.014*\"президент\" + 0.013*\"правительство\" + 0.013*\"политический\" + 0.010*\"совет\" + 0.010*\"организация\" + 0.009*\"министр\" + 0.009*\"стать\" + 0.009*\"страна\" + 0.009*\"республика\"')\n",
    "\n",
    "* 0.035*\"армия\" + 0.035*\"войско\" + 0.029*\"фронт\" + 0.029*\"город\" + 0.022*\"противник\" + 0.018*\"наступление\" + 0.018*\"январь\" + 0.017*\"район\" + 0.016*\"часть\" + 0.014*\"операция\"')\n",
    "\n",
    "\n",
    "Теперь обучим еще три модели с tfidf, в первой оставим \"дефолтные\" значения с пары, во второй сделаем больше тем, в третьей - больше проходов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lda_tf_1 = gensim.models.LdaMulticore(corpus, 100, id2word=dictionary, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lda_tf_1.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-25.745204181229308"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_tf_1.log_perplexity(corpus[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 2s\n",
      "Parser   : 168 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lda_tf_2 = gensim.models.LdaMulticore(corpus, 150, id2word=dictionary, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lda_tf_2.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-53.74885792530168"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_tf_2.log_perplexity(corpus[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 38s\n",
      "Parser   : 102 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lda_tf_3 = gensim.models.LdaMulticore(corpus, 100, id2word=dictionary, passes=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lda_tf_3.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-28.455099451667664"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_tf_3.log_perplexity(corpus[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшая модель, как ни странно, - первая, где минимальное количество тем и проходов. Но все три почему-то получились значительно хуже, чем bow, и на вид, и по перплексии. Хотя иногда в них попадаются интересные топики, которых не встретилось в bow, например, этот:\n",
    "\n",
    "* 0.077*\"граф\" + 0.043*\"графство\" + 0.039*\"i\" + 0.035*\"де\" + 0.031*\"ii\" + 0.031*\"герцог\" + 0.031*\"iii\" + 0.026*\"сын\" + 0.026*\"бургундия\" + 0.023*\"король\"')\n",
    "\n",
    "А вообще темы у моделей lda_2 и lda_tf_1 (которые мы считаем лучшими), кажется, вообще не совпадают, это как-то странно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "stexts = [' '.join(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем матрицу слова-документы с помощью TfidfVectorizer и CountVectorizer с одинаковыми параметрами, потом сравним их между собой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer1 = TfidfVectorizer(max_features=2000, min_df=10, max_df=0.3, ngram_range=(1,2))\n",
    "X1 = vectorizer1.fit_transform(stexts)                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer2 = CountVectorizer(max_features=2000, min_df=10, max_df=0.3, ngram_range=(1,2))\n",
    "X2 = vectorizer2.fit_transform(stexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разложение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
       "    n_components=100, random_state=None, shuffle=False, solver='cd', tol=0.0001,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = NMF(n_components=100)\n",
    "model1.fit(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
       "    n_components=100, random_state=None, shuffle=False, solver='cd', tol=0.0001,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = NMF(n_components=100)\n",
    "model2.fit(X2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отобразим темы первой модели и ее точность:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# feat_names_1 = vectorizer1.get_feature_names()\n",
    "# top_words = model1.components_.argsort()[:,:-5:-1]\n",
    "\n",
    "# for i in range(top_words.shape[0]):\n",
    "#     words = [feat_names_1[j] for j in top_words[i]]\n",
    "#     print(i, \"--\".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1225.116505459658"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.reconstruction_err_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И то же самое для второй:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat_names_2 = vectorizer2.get_feature_names()\n",
    "# top_words = model2.components_.argsort()[:,:-5:-1]\n",
    "\n",
    "# for i in range(top_words.shape[0]):\n",
    "#     words = [feat_names_2[j] for j in top_words[i]]\n",
    "#     print(i, \"--\".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1226.3888384505683"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.reconstruction_err_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрики у них, конечно, совсем большие, но темы выглядят неплохо. Возьмем tfidf-векторайзер и попробуем увеличить количество тем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
       "    n_components=200, random_state=None, shuffle=False, solver='cd', tol=0.0001,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = NMF(n_components=200)\n",
    "model3.fit(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_words = model3.components_.argsort()[:,:-5:-1]\n",
    "\n",
    "# for i in range(top_words.shape[0]):\n",
    "#     words = [feat_names_1[j] for j in top_words[i]]\n",
    "#     print(i, \"--\".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.96642475174846"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.reconstruction_err_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С увеличением количества тем точность стала гораздо выше, так что лучшей считаем последнюю из этих трех моделей. Многие темы у NMF хотя бы частично совпадают с темами из LDA (автомобили, спорт, география). \n",
    "\n",
    "Вот некоторые удачные:\n",
    "\n",
    "* фильм--режиссёр--снять--снятой\n",
    "\n",
    "* турнир--финал--профессиональный--победитель\n",
    "\n",
    "* художник--искусство--живопись--выставка\n",
    "\n",
    "* флаг--символ--цвета--герб\n",
    "\n",
    "Правда, иногда три слова из четырех образуют тему, а последнее как-то выпадает:\n",
    "\n",
    "* герой--социалистический--труд--сайт\n",
    "\n",
    "* римский--папа--католический--китай"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
